{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9534c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew-misnik/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import Dice\n",
    "from torchmetrics import MeanSquaredError\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as functional\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e3854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "split = pd.read_csv(\"split.csv\")\n",
    "learning_rate = 0.01\n",
    "epoch_num = 51\n",
    "\n",
    "data_train = []\n",
    "sem_train = []\n",
    "data_dev = []\n",
    "sem_dev = []\n",
    "data_test = []\n",
    "sem_test = []\n",
    "\n",
    "for _, row in split.iterrows():\n",
    "    img = cv2.resize(cv2.imread(row['img_path']), (2**8, 2**8), interpolation = cv2.INTER_AREA)\n",
    "    sem = cv2.resize(np.delete(cv2.imread(row['sem_path']), (1, 2), 2), (2**8, 2**8), interpolation = cv2.INTER_AREA)\n",
    "    def bool(x):\n",
    "        return (x > 0)\n",
    "    sem = np.vectorize(bool)(sem)\n",
    "    if row['split'] == 'train':\n",
    "        data_train.append(img)\n",
    "        sem_train.append(sem)\n",
    "    if row['split'] == 'dev':\n",
    "        data_dev.append(img)\n",
    "        sem_dev.append(sem)\n",
    "    if row['split'] == 'test':\n",
    "        data_test.append(img)\n",
    "        sem_test.append(sem)\n",
    "\n",
    "data_train = torch.FloatTensor(np.array(data_train)).to(device)\n",
    "sem_train = torch.FloatTensor(np.array(sem_train)).to(device)\n",
    "data_dev = torch.FloatTensor(np.array(data_dev)).to(device)\n",
    "sem_dev = torch.FloatTensor(np.array(sem_dev)).to(device)\n",
    "data_test = torch.FloatTensor(np.array(data_test)).to(device)\n",
    "sem_test = torch.FloatTensor(np.array(sem_test)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78eb2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size=2)\n",
    "        self.conv_2 = nn.Conv2d(out_channels, out_channels, kernel_size=2)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.batchnorm(self.conv_1(x)))\n",
    "        x = self.activation(self.batchnorm(self.conv_2(x)))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv_1 = Conv(3, 2**6)\n",
    "        self.conv_2 = Conv(2**6, 2**7)\n",
    "        self.conv_3 = Conv(2**7, 2**8)\n",
    "        self.conv_4 = Conv(2**8, 2**9)\n",
    "        self.conv_5 = Conv(2**9, 2**10)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv_1(x)\n",
    "        x = self.pool(x1)\n",
    "        x2 = self.conv_2(x)\n",
    "        x = self.pool(x2)\n",
    "        x3 = self.conv_3(x)\n",
    "        x = self.pool(x3)\n",
    "        x4 = self.conv_4(x)\n",
    "        x = self.pool(x4)\n",
    "        return (self.conv_5(x), x1, x2, x3, x4)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.out_shape = (2**8, 2**8)\n",
    "        self.back_1 = nn.ConvTranspose2d(2**10, 2**9, kernel_size=2, stride=2)\n",
    "        self.conv_1 = Conv(2**10, 2**9)\n",
    "        self.back_2 = nn.ConvTranspose2d(2**9, 2**8, kernel_size=2, stride=2)\n",
    "        self.conv_2 = Conv(2**9, 2**8)\n",
    "        self.back_3 = nn.ConvTranspose2d(2**8, 2**7, kernel_size=2, stride=2)\n",
    "        self.conv_3 = Conv(2**8, 2**7)\n",
    "        self.back_4 = nn.ConvTranspose2d(2**7, 2**6, kernel_size=2, stride=2)\n",
    "        self.conv_4 = Conv(2**7, 2**6)\n",
    "        self.conv_5 = nn.Conv2d(2**6, 1, kernel_size=1)\n",
    "\n",
    "    def pad(self, tensor, shape):\n",
    "        dW = shape[-1] - tensor.shape[-1]\n",
    "        dH = shape[-2] - tensor.shape[-2]\n",
    "        val_w = dW // 2\n",
    "        val_h = dH // 2\n",
    "        return functional.pad(tensor, [val_w, dW - val_w, val_h, dH - val_h])\n",
    "\n",
    "    def forward(self, x, x1, x2, x3, x4):\n",
    "        x = torch.cat([x4, self.pad(self.back_1(x), x4.shape)], dim=1)\n",
    "        x = torch.cat([x3, self.pad(self.back_2(self.conv_1(x)), x3.shape)], dim=1)\n",
    "        x = torch.cat([x2, self.pad(self.back_3(self.conv_2(x)), x2.shape)], dim=1)\n",
    "        x = torch.cat([x1, self.pad(self.back_4(self.conv_3(x)), x1.shape)], dim=1)\n",
    "        return torch.sigmoid(self.pad(self.conv_5(self.conv_4(x)), self.out_shape))\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.permute(x, (0, 3, 1, 2))\n",
    "        x, x1, x2, x3, x4 = self.encoder(x)\n",
    "        x = self.decoder(x, x1, x2, x3, x4)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bc2a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "lossfunction = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa320e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0 loss =  0.4110845\n",
      "epoch = 10 loss =  0.07000518\n",
      "epoch = 20 loss =  0.084308356\n",
      "epoch = 30 loss =  0.048253164\n",
      "epoch = 40 loss =  0.367396\n"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(epoch_num):\n",
    "    idx = np.random.randint(len(data_train), size=4)\n",
    "    data_batch = data_train[idx]\n",
    "    y_batch = sem_train[idx]\n",
    "    \n",
    "    predictions = torch.squeeze(model(data_batch), dim=1)\n",
    "    \n",
    "    loss = lossfunction(predictions, y_batch)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    loss.data.numpy()\n",
    "    if epoch_num % 10 == 0:\n",
    "        print('epoch =', epoch_num, 'loss = ', loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4b4748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffFgMSE value =  tensor(0.0249)\n",
      "DiffFgDICE value =  tensor(0.9751)\n",
      "image results/result_2.png successfuly saved  2023-07-30 16:35:45.134532\n",
      "image results/result_5.png successfuly saved  2023-07-30 16:35:45.153313\n",
      "image results/result_8.png successfuly saved  2023-07-30 16:35:45.171563\n",
      "image results/result_11.png successfuly saved  2023-07-30 16:35:45.187328\n",
      "image results/result_14.png successfuly saved  2023-07-30 16:35:45.202146\n",
      "image results/result_17.png successfuly saved  2023-07-30 16:35:45.220131\n",
      "image results/result_20.png successfuly saved  2023-07-30 16:35:45.236726\n",
      "image results/result_23.png successfuly saved  2023-07-30 16:35:45.253441\n",
      "image results/result_26.png successfuly saved  2023-07-30 16:35:45.271508\n",
      "image results/result_29.png successfuly saved  2023-07-30 16:35:45.290904\n",
      "image results/result_32.png successfuly saved  2023-07-30 16:35:45.309110\n",
      "image results/result_35.png successfuly saved  2023-07-30 16:35:45.325247\n",
      "image results/result_38.png successfuly saved  2023-07-30 16:35:45.341788\n",
      "image results/result_41.png successfuly saved  2023-07-30 16:35:45.357854\n",
      "image results/result_44.png successfuly saved  2023-07-30 16:35:45.375337\n",
      "image results/result_47.png successfuly saved  2023-07-30 16:35:45.392834\n",
      "image results/result_50.png successfuly saved  2023-07-30 16:35:45.410133\n",
      "image results/result_53.png successfuly saved  2023-07-30 16:35:45.427442\n",
      "image results/result_56.png successfuly saved  2023-07-30 16:35:45.443471\n",
      "image results/result_59.png successfuly saved  2023-07-30 16:35:45.462542\n",
      "image results/result_62.png successfuly saved  2023-07-30 16:35:45.480680\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test = model(data_test)\n",
    "test = test.detach().apply_(lambda x: (0 if x <= 0.5 else 1))\n",
    "test = torch.squeeze(test, dim=1)\n",
    "\n",
    "# print(\"(dev) loss value = \", lossfunction(torch.squeeze(test, dim=1), sem_test).data)\n",
    "print(\"DiffFgMSE value = \", MeanSquaredError()(test, sem_test))\n",
    "print(\"DiffFgDICE value = \", Dice()(test.type(torch.LongTensor), sem_test.type(torch.LongTensor)))\n",
    "\n",
    "for (index, image) in enumerate(test):\n",
    "    file_path = 'results/result_{num}.png'.format(num=index)\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "    save_image(image * 255, file_path)\n",
    "    if (index % 3 == 2):\n",
    "        print('image', file_path, 'successfuly saved ', datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
